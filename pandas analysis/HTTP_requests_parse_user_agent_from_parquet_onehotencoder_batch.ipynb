{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "DATA_DIR = '/home/nsuprotivniy/Documents/Работа/OKru/Antispam/data/'\n",
    "GRAPH_PATH = '/home/nsuprotivniy/Documents/Работа/OKru/Antispam/graph/'\n",
    "MODEL_DIR = '/home/nsuprotivniy/Documents/Работа/OKru/Antispam/model/'\n",
    "SAMPLE_SIZE = 1000 # -1 если использовать все даннные\n",
    "BATCH_SIZE = 1_000_000\n",
    "DEPTH_RANGE = range(1, 20, 2)\n",
    "KNN_NEIGHBORS_RANGE = range(1, 20, 2)\n",
    "SVM_MAX_ITER_RANGE = range(10, 100, 10)\n",
    "SVM_ALPHA_RANGE = np.fromfunction(lambda i: 0.0000001 * pow(10, i), (7,), dtype=float)\n",
    "\n",
    "FEATURES = [\n",
    "    'userAgentIsBot',\n",
    "    'userAgentIsMobile',\n",
    "    'userAgentIsTablet',\n",
    "    'userAgentIsTouchCapable',\n",
    "    'userAgentIsPC',\n",
    "    'userAgentOSFamily',\n",
    "    'userAgentOSVersion0',\n",
    "    'userAgentOSVersion1',\n",
    "    'userAgentOSVersion2',\n",
    "    'userAgentBrowserFamily',\n",
    "    'userAgentBrowserVersion0',\n",
    "    'userAgentBrowserVersion1',\n",
    "    'userAgentBrowserVersion2',\n",
    "    'userAgentDeviceFamily',\n",
    "    'userAgentDeviceBrand',\n",
    "    'userAgentDeviceModel',\n",
    "    'from',\n",
    "    'to',\n",
    "    'url',\n",
    "    'requestType',\n",
    "    'operation'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /home/nsuprotivniy/anaconda3/lib/python3.6/site-packages\n",
      "Requirement already satisfied: numpy>=1.10 in /home/nsuprotivniy/anaconda3/lib/python3.6/site-packages (from pyarrow)\n",
      "Requirement already satisfied: six>=1.0.0 in /home/nsuprotivniy/anaconda3/lib/python3.6/site-packages (from pyarrow)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import seaborn as sns\n",
    "import user_agents\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "http = pq.read_table(DATA_DIR + 'botsHTTPRequests-20180217_1718_parsedUA.parquet', columns=FEATURES ).to_pandas().head(SAMPLE_SIZE)\n",
    "target = pq.read_table(DATA_DIR + 'botsHTTPRequests-20180217_1718_parsedUA.parquet', columns=['isBot'] ).to_pandas().head(SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготока моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hashing Trick - единственный нормальный подход https://habr.com/company/ods/blog/326418/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashingTrick(TransformerMixin):\n",
    "    \n",
    "    _default_hashing_trick_modulars = {\n",
    "        'userAgentOSFamily': 10000,\n",
    "        'userAgentDeviceFamily': 10000,\n",
    "        'userAgentDeviceBrand': 10000,\n",
    "        'userAgentDeviceModel': 10000,\n",
    "        'userAgentBrowserFamily': 10000,\n",
    "        'from': 10000,\n",
    "        'to': 10000,\n",
    "        'url': 10000000,\n",
    "        'requestType': 10000,\n",
    "        'operation': 10000\n",
    "    }\n",
    "    \n",
    "    def __init__(self, hashing_trick_modulars = _default_hashing_trick_modulars):\n",
    "        self.hashing_trick_modulars = hashing_trick_modulars\n",
    "    \n",
    "    def set_params(self, **kwargs):\n",
    "        \"\"\"Set the parameters of this estimator.\"\"\"\n",
    "    \n",
    "    def get_params(self, **kwargs):\n",
    "        return {\"hashing_trick_modulars\": self.hashing_trick_modulars}\n",
    "        \n",
    "    def _hashing_trick(self, x, n):\n",
    "        return hash(x) % n\n",
    "\n",
    "    def _column_hashing_trick(self, col_name):\n",
    "        self.http[col_name] = self.http[col_name].apply(self._hashing_trick, args=(self.hashing_trick_modulars[col_name],))\n",
    "    \n",
    "    def _to_numeric(self, col_name):\n",
    "        self.http[col_name] = pd.to_numeric(self.http[col_name], 'coerce').fillna(0).astype(int)\n",
    "    \n",
    "    def fit_transform(self, X, *_):\n",
    "        return self.transform(X)\n",
    "        \n",
    "    def transform(self, X, *_):\n",
    "        self.http = X\n",
    "        self._column_hashing_trick('userAgentOSFamily')\n",
    "        self._column_hashing_trick('userAgentDeviceFamily')\n",
    "        self._column_hashing_trick('userAgentDeviceBrand')\n",
    "        self._column_hashing_trick('userAgentDeviceModel')\n",
    "        self._column_hashing_trick('userAgentBrowserFamily')\n",
    "        self._column_hashing_trick('from')\n",
    "        self._column_hashing_trick('to')\n",
    "        self._column_hashing_trick('url')\n",
    "        self._column_hashing_trick('requestType')\n",
    "        self._column_hashing_trick('operation')\n",
    "        \n",
    "        self._to_numeric('userAgentOSVersion0')\n",
    "        self._to_numeric('userAgentOSVersion1')\n",
    "        self._to_numeric('userAgentOSVersion2')\n",
    "        self._to_numeric('userAgentBrowserVersion0')\n",
    "        self._to_numeric('userAgentBrowserVersion1')\n",
    "        self._to_numeric('userAgentBrowserVersion2')\n",
    "        return self.http\n",
    "    \n",
    "    def fit(self, *_):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht = HashingTrick()\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "clf = SGDClassifier(random_state=17, max_iter=1000, alpha=0.0000001, loss='log')\n",
    "pipeline = Pipeline(\n",
    "    [('ht', ht)] +\n",
    "    [('ohe', ohe)]+\n",
    "    [('sgd', clf)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск гиперпаратметров\n",
    "#### Используется RandomizedSearchCV, так полный GridSearchCV работает долго"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_holdout, y_train, y_holdout = train_test_split(http, target, test_size=0.1, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   33.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   43.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sgd__max_iter': 80, 'sgd__alpha': 0.001} 0.897702478678218\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      users       0.90      0.87      0.89        54\n",
      "       bots       0.85      0.89      0.87        46\n",
      "\n",
      "avg / total       0.88      0.88      0.88       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {'sgd__alpha': (0.1, 0.01, 0.001, 0.00001, 0.0000001),\n",
    "              'sgd__max_iter': (5, 10, 50, 80, 500, 1000)}\n",
    "search = RandomizedSearchCV(pipeline, params, cv=5, n_jobs=-1, verbose=True, scoring='f1', n_iter = 10)\n",
    "search.fit(X_train, y_train)\n",
    "print(search.best_params_, search.best_score_)\n",
    "print(classification_report(y_holdout, search.predict(X_holdout), target_names = ['users', 'bots']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание моделей по полученным из search гиперпараметрам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SGDClassifier(random_state = 17, \n",
    "                    max_iter = search.best_params_['sgd__max_iter'], \n",
    "                    alpha = search.best_params_['sgd__alpha'],\n",
    "                    loss = 'log')\n",
    "ht = HashingTrick().fit(http)\n",
    "ohe = OneHotEncoder(handle_unknown='ignore').fit(ht.transform(http))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/nsuprotivniy/Documents/Работа/OKru/Antispam/model/http_ua_from_parquet_onehotencoder_sgd.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(ht, MODEL_DIR + 'http_ua_from_parquet_onehotencoder_hasging_trick.pkl') \n",
    "joblib.dump(ohe, MODEL_DIR + 'http_ua_from_parquet_onehotencoder_ohe.pkl')\n",
    "joblib.dump(clf, MODEL_DIR + 'http_ua_from_parquet_onehotencoder_sgd.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение на большой выборке "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht = joblib.load(MODEL_DIR + 'http_ua_from_parquet_onehotencoder_hasging_trick.pkl') \n",
    "ohe = joblib.load(MODEL_DIR + 'http_ua_from_parquet_onehotencoder_ohe.pkl')\n",
    "clf = joblib.load(MODEL_DIR + 'http_ua_from_parquet_onehotencoder_sgd.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = pq.read_table(DATA_DIR + 'botsHTTPRequests-20180217_1718_parsedUA.parquet', \n",
    "                        columns=FEATURES + ['isBot']).to_batches(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = True\n",
    "for batch in train_batches:\n",
    "    http = batch.to_pandas()\n",
    "    X = http[FEATURES]\n",
    "    y = http['isBot']\n",
    "    X = ht.transform(X)\n",
    "    X = ohe.transform(X)\n",
    "    if (first):\n",
    "        clf.fit(X, y) # Проблема, когда 'y' состоит только из пользователей\n",
    "        first = False\n",
    "    else:\n",
    "        clf.partial_fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/nsuprotivniy/Documents/Работа/OKru/Antispam/model/http_ua_from_parquet_onehotencoder_sgd_fitted.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, MODEL_DIR + 'http_ua_from_parquet_onehotencoder_sgd_fitted.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация для большой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht = joblib.load(MODEL_DIR + 'http_ua_from_parquet_onehotencoder_hasging_trick.pkl') \n",
    "ohe = joblib.load(MODEL_DIR + 'http_ua_from_parquet_onehotencoder_ohe.pkl')\n",
    "clf = joblib.load(MODEL_DIR + 'http_ua_from_parquet_onehotencoder_sgd_fitted.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_batches = pq.read_table(DATA_DIR + 'botsHTTPRequests-20180217_1718_parsedUA.parquet', \n",
    "                        columns=FEATURES + ['isBot']).to_batches(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_writer = pq.ParquetWriter(DATA_DIR + 'botsHTTPRequests-20180217_1718_parsedUA_predicted.parquet', \n",
    "                                    pa.Table.from_pandas(pd.DataFrame({'predict_proba': []}, dtype=np.float64)).schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in predict_batches:\n",
    "    http = batch.to_pandas()\n",
    "    X = http[FEATURES]\n",
    "    X = ht.transform(X)\n",
    "    X = ohe.transform(X)\n",
    "    predicted = clf.predict_proba(X)\n",
    "    table = pa.Table.from_pandas(pd.DataFrame({'predict_proba': predicted[:,1]}, dtype=np.float64))\n",
    "    predicted_writer.write_table(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование для большой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_proba = pq.read_table(DATA_DIR + 'botsHTTPRequests-20180217_1718_parsedUA_predicted.parquet',\n",
    "                                columns=['predict_proba']).to_pandas()\n",
    "\n",
    "real = pq.read_table(DATA_DIR + 'botsHTTPRequests-20180217_1718_parsedUA.parquet',\n",
    "                                columns=['isBot']).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bound = 0.5\n",
    "predicted = (predicted_proba.values.ravel() > bound).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      users       0.98      1.00      0.99   1010370\n",
      "       bots       0.88      0.02      0.03     20751\n",
      "\n",
      "avg / total       0.98      0.98      0.97   1031121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(real, predicted, target_names = ['users', 'bots']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
